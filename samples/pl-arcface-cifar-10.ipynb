{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b210ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f597078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a395c9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f0ab5c94280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc6eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFaceLoss(nn.Module):\n",
    "    def __init__(self, num_classes, embedding_size, margin, scale):\n",
    "        \"\"\"\n",
    "        ArcFace: Additive Angular Margin Loss for Deep Face Recognition\n",
    "        (https://arxiv.org/pdf/1801.07698.pdf)\n",
    "        Args:\n",
    "            num_classes: The number of classes in your training dataset\n",
    "            embedding_size: The size of the embeddings that you pass into\n",
    "            margin: m in the paper, the angular margin penalty in radians\n",
    "            scale: s in the paper, feature scale\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_size = embedding_size\n",
    "        self.margin = margin\n",
    "        self.scale = scale\n",
    "        \n",
    "        self.W = torch.nn.Parameter(torch.Tensor(num_classes, embedding_size))\n",
    "        nn.init.xavier_normal_(self.W)\n",
    "        \n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (None, embedding_size)\n",
    "            labels: (None,)\n",
    "        Returns:\n",
    "            loss: scalar\n",
    "        \"\"\"\n",
    "        cosine = self.get_cosine(embeddings) # (None, n_classes)\n",
    "        mask = self.get_target_mask(labels) # (None, n_classes)\n",
    "        cosine_of_target_classes = cosine[mask == 1] # (None, )\n",
    "        modified_cosine_of_target_classes = self.modify_cosine_of_target_classes(\n",
    "            cosine_of_target_classes\n",
    "        ) # (None, )\n",
    "        diff = (modified_cosine_of_target_classes - cosine_of_target_classes).unsqueeze(1) # (None,1)\n",
    "        logits = cosine + (mask * diff) # (None, n_classes)\n",
    "        logits = self.scale_logits(logits) # (None, n_classes)\n",
    "        return nn.CrossEntropyLoss()(logits, labels)\n",
    "        \n",
    "    def get_cosine(self, embeddings):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (None, embedding_size)\n",
    "        Returns:\n",
    "            cosine: (None, n_classes)\n",
    "        \"\"\"\n",
    "        cosine = F.linear(F.normalize(embeddings), F.normalize(self.W))\n",
    "        return cosine\n",
    "    \n",
    "    def get_target_mask(self, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels: (None,)\n",
    "        Returns:\n",
    "            mask: (None, n_classes)\n",
    "        \"\"\"\n",
    "        batch_size = labels.size(0)\n",
    "        onehot = torch.zeros(batch_size, self.num_classes, device=labels.device)\n",
    "        onehot.scatter_(1, labels.unsqueeze(-1), 1)\n",
    "        return onehot\n",
    "        \n",
    "    def modify_cosine_of_target_classes(self, cosine_of_target_classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cosine_of_target_classes: (None,)\n",
    "        Returns:\n",
    "            modified_cosine_of_target_classes: (None,)\n",
    "        \"\"\"\n",
    "        eps = 1e-6\n",
    "        # theta in the paper\n",
    "        angles = torch.acos(torch.clamp(cosine_of_target_classes, -1 + eps, 1 - eps))\n",
    "        return torch.cos(angles + self.margin)\n",
    "    \n",
    "    def scale_logits(self, logits):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits: (None, n_classes)\n",
    "        Returns:\n",
    "            scaled_logits: (None, n_classes)\n",
    "        \"\"\"\n",
    "        return logits * self.scale\n",
    "    \n",
    "class SoftmaxLoss(nn.Module):\n",
    "    def __init__(self, num_classes, embedding_size):\n",
    "        \"\"\"\n",
    "        Regular softmax loss (1 fc layer without bias + CrossEntropyLoss)\n",
    "        Args:\n",
    "            num_classes: The number of classes in your training dataset\n",
    "            embedding_size: The size of the embeddings that you pass into\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.W = torch.nn.Parameter(torch.Tensor(num_classes, embedding_size))\n",
    "        nn.init.xavier_normal_(self.W)\n",
    "        \n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (None, embedding_size)\n",
    "            labels: (None,)\n",
    "        Returns:\n",
    "            loss: scalar\n",
    "        \"\"\"\n",
    "        logits = F.linear(embeddings, self.W)\n",
    "        return nn.CrossEntropyLoss()(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f3c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # (None, 16, 5, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, embedding_size, loss_type, max_epochs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters('max_epochs')\n",
    "        self.embedder = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(100),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(embedding_size)\n",
    "        )\n",
    "        \n",
    "        if loss_type == 'arcface':\n",
    "            self.loss_function = ArcFaceLoss(\n",
    "                num_classes=10, \n",
    "                embedding_size=embedding_size,\n",
    "                margin=0.3, \n",
    "                scale=30.0\n",
    "            )\n",
    "        elif loss_type == 'softmax':\n",
    "            self.loss_function = SoftmaxLoss(num_classes=10, embedding_size=embedding_size)\n",
    "           \n",
    "    def forward(self, x):\n",
    "        return self.embedder(x) # (None, embedding_size)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        embeddings = self.embedder(x) # (None, embedding_size)\n",
    "        loss = self.loss_function(embeddings, y)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        embeddings = self.embedder(x) # (None, embedding_size)\n",
    "        return {'embeddings': embeddings, 'labels': y}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f891f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(trainer, model, loader, title):\n",
    "    outputs = trainer.predict(model, loader)\n",
    "    embeddings = F.normalize(torch.cat([output['embeddings'] for output in outputs])).numpy()\n",
    "    labels = torch.cat([output['labels'] for output in outputs]).numpy()\n",
    "    \n",
    "    colors = [\"red\", \"black\", \"yellow\", \"green\", \"pink\",\n",
    "              \"gray\", \"lightgreen\", \"orange\", \"blue\", \"teal\"]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(embeddings[:,0], embeddings[:,1], \n",
    "                color=[colors[label] for label in labels])\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-1.2, 1.2])\n",
    "    ax.set_ylim([-1.2, 1.2])\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3128edcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:410: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name          | Type        | Params\n",
      "----------------------------------------------\n",
      "0 | embedder      | Sequential  | 2.9 K \n",
      "1 | loss_function | ArcFaceLoss | 5.1 K \n",
      "----------------------------------------------\n",
      "8.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.0 K     Total params\n",
      "0.032     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008074045181274414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9574462baee43429c171244d198e392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007386684417724609,
       "initial": 1563,
       "n": 1563,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a77d4dba22416f82aa5577614a9483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1563it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_size = 512\n",
    "max_epochs = 100\n",
    "arcface_model = Model(embedding_size=embedding_size, loss_type='arcface', max_epochs=max_epochs)\n",
    "\n",
    "\n",
    "arcface_trainer = pl.Trainer(accelerator=\"gpu\", devices=1, log_every_n_steps=10, max_epochs=max_epochs)\n",
    "arcface_trainer.fit(arcface_model, train_loader)\n",
    "visualize(arcface_trainer, arcface_model, val_loader, f'arcface (epoch {max_epochs})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce8e026",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mTensor\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e429605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569a3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual3d(trainer, model, loader, title):\n",
    "    outputs = trainer.predict(model, loader)\n",
    "    embeddings = F.normalize(torch.cat([output['embeddings'] for output in outputs])).numpy()\n",
    "    labels = torch.cat([output['labels'] for output in outputs]).numpy()\n",
    "    \n",
    "    tsne_df = pd.DataFrame(\n",
    "        np.column_stack((embeddings, labels)),\n",
    "        columns = [\"x\",\"y\",\"z\",\"targets\"]\n",
    "    )\n",
    "\n",
    "    fig = px.scatter_3d(tsne_df, x='x', y='y', z='z',\n",
    "                  color='targets')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c6c2343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007277488708496094,
       "initial": 1563,
       "n": 1563,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a6b3badbe746eea9758f6b84487abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1563it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (10000, 513), indices imply (10000, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvisual3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43marcface_trainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marcface_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marcface (epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mvisual3d\u001b[0;34m(trainer, model, loader, title)\u001b[0m\n\u001b[1;32m      3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(torch\u001b[38;5;241m.\u001b[39mcat([output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]))\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs])\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 6\u001b[0m tsne_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtargets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mscatter_3d(tsne_df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, z\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m               color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/arcface/lib/python3.8/site-packages/pandas/core/frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    692\u001b[0m         )\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/anaconda3/envs/arcface/lib/python3.8/site-packages/pandas/core/internals/construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    349\u001b[0m )\n\u001b[0;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/arcface/lib/python3.8/site-packages/pandas/core/internals/construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (10000, 513), indices imply (10000, 4)"
     ]
    }
   ],
   "source": [
    "visual3d(arcface_trainer, arcface_model, val_loader, f'arcface (epoch {max_epochs})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff7fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007646799087524414,
       "initial": 1563,
       "n": 1563,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010a999b49f2479fba90ac9a1310c981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1563it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05811983 -0.03804059  0.03145459 ...  0.03714435  0.06093874\n",
      "  -0.05402192]\n",
      " [-0.05811903 -0.0380403   0.03145385 ...  0.03714465  0.0609387\n",
      "  -0.0540222 ]\n",
      " [-0.05811908 -0.03804024  0.03145453 ...  0.03714395  0.0609386\n",
      "  -0.05402212]\n",
      " ...\n",
      " [-0.05811938 -0.03804059  0.03145479 ...  0.03714392  0.06093816\n",
      "  -0.05402228]\n",
      " [-0.05811884 -0.03804064  0.03145443 ...  0.03714402  0.06093825\n",
      "  -0.05402256]\n",
      " [-0.05811922 -0.03804031  0.0314545  ...  0.03714432  0.06093856\n",
      "  -0.05402196]]\n",
      "<class 'numpy.ndarray'>\n",
      "(10000, 512)\n",
      "[-5.81198260e-02 -3.80405895e-02  3.14545929e-02 -4.04466363e-03\n",
      "  3.53434794e-02  1.43111283e-02  3.32801640e-02  5.54810204e-02\n",
      "  1.80661818e-03 -7.02690333e-02 -6.95419908e-02  6.12184852e-02\n",
      " -4.50285040e-02 -3.87282576e-03 -2.15985086e-02  4.66160588e-02\n",
      "  6.47629201e-02 -2.23289728e-02 -4.09954116e-02 -4.82871309e-02\n",
      "  7.01069832e-02  2.17528716e-02 -4.78264987e-02  7.36553147e-02\n",
      " -5.47420047e-02  5.61050996e-02 -1.71398595e-02 -2.66358443e-02\n",
      " -5.61278872e-03 -7.12019131e-02 -1.16366409e-02 -1.49654523e-02\n",
      "  2.09737495e-02  2.42331289e-02  2.93106474e-02 -3.34859230e-02\n",
      " -7.75713325e-02  5.00055589e-02  5.03394306e-02 -5.82121834e-02\n",
      "  4.46918234e-02  4.16914076e-02  3.65139022e-02  3.62936780e-02\n",
      "  5.96260577e-02 -2.65496504e-02  7.09087923e-02  7.16233402e-02\n",
      " -6.35466203e-02 -9.09541771e-02 -3.30475308e-02 -8.04577023e-02\n",
      "  1.82378720e-02 -5.46024479e-02  4.76082228e-02  4.88427281e-02\n",
      "  1.37801366e-02 -2.96664070e-02 -2.89041828e-02 -1.63303446e-02\n",
      "  5.14463186e-02 -9.60319070e-04 -3.87585396e-03 -6.70126230e-02\n",
      " -1.99770788e-03  6.42067343e-02 -2.25172043e-02  7.69856125e-02\n",
      "  4.28372100e-02  3.52101475e-02  3.01152822e-02 -5.46398796e-02\n",
      " -1.09563991e-02  2.50412431e-02  8.67091026e-03 -6.10916177e-03\n",
      " -8.51610675e-03 -3.54924202e-02  5.95308617e-02 -1.78877916e-02\n",
      " -8.10339525e-02  5.41942567e-02 -7.01088784e-03 -5.31422570e-02\n",
      "  4.13718522e-02 -6.94238171e-02  6.05162121e-02 -1.15851834e-02\n",
      " -3.24408486e-02  1.54136028e-02  4.66138832e-02  8.29317272e-02\n",
      " -6.31857589e-02 -5.26770055e-02  6.06819242e-02  3.71985659e-02\n",
      " -3.77531070e-03  5.66557422e-02  6.39016181e-03  3.22894342e-02\n",
      " -3.23648266e-02 -3.44201401e-02 -7.00521516e-03 -6.11270368e-02\n",
      "  6.25937432e-02 -2.45033726e-02 -7.51928911e-02  3.83379422e-02\n",
      " -4.31459285e-02  5.18928841e-02 -7.11131021e-02  6.16819561e-02\n",
      " -1.05889421e-02 -6.83117062e-02 -1.63109861e-02  3.75364237e-02\n",
      " -2.42539328e-02 -5.26497923e-02  1.63231548e-02  6.84172362e-02\n",
      "  5.40064871e-02  7.82197863e-02 -4.64657210e-02 -3.39075476e-02\n",
      " -3.28383781e-02  9.17326100e-03 -4.97807115e-02 -6.41364604e-02\n",
      "  3.24701667e-02  5.50058149e-02 -8.00609365e-02 -8.59539211e-03\n",
      "  1.87847801e-02 -1.57318804e-02 -8.31972621e-03  4.22113426e-02\n",
      "  5.89550324e-02  4.59137820e-02  1.97547916e-02 -1.90037545e-02\n",
      " -4.40799557e-02  1.72467269e-02 -2.63954513e-03 -4.81098965e-02\n",
      "  7.61355385e-02 -5.97729087e-02  2.72575468e-02  7.12400153e-02\n",
      "  6.47919020e-03 -7.67157525e-02  2.94862711e-03  5.29443994e-02\n",
      "  7.36659244e-02  4.85305749e-02 -8.40396155e-03 -5.98490797e-02\n",
      " -3.57080810e-02 -2.41060611e-02  3.31765153e-02  4.10843780e-03\n",
      " -5.62707409e-02  5.82815818e-02 -6.72073215e-02 -9.84577741e-03\n",
      "  5.77722490e-02 -5.78207187e-02  5.13461605e-03  2.73174979e-02\n",
      " -3.25010195e-02  2.00364403e-02  1.91155244e-02  4.25298810e-02\n",
      " -3.91151709e-03  1.69555917e-02  4.84054238e-02 -1.57932155e-02\n",
      "  1.45871891e-03 -1.51536390e-02 -4.98099551e-02 -4.90091704e-02\n",
      "  2.56462414e-02  2.59293225e-02  4.19780426e-02 -2.90697794e-02\n",
      " -9.44075081e-03 -3.92066091e-02  6.17062151e-02 -4.61373590e-02\n",
      " -4.06965949e-02 -4.14613970e-02 -2.82143964e-03  3.44521925e-02\n",
      " -1.41035682e-02 -6.80440590e-02 -5.23102693e-02  1.42283430e-02\n",
      "  8.39118734e-02  5.70689589e-02  5.86974472e-02 -5.69737144e-02\n",
      "  1.26865122e-03  2.82989610e-02  4.14510928e-02  7.98285455e-02\n",
      " -3.02222744e-02 -2.42436398e-03  6.48630857e-02  9.80464742e-02\n",
      " -5.40346093e-02 -4.86029796e-02  5.54800443e-02 -9.33292881e-03\n",
      "  2.19437270e-03 -4.39675450e-02  3.85420360e-02 -4.69509838e-03\n",
      " -5.94977438e-02  7.74843767e-02 -6.88421056e-02  5.13179526e-02\n",
      " -1.78197436e-02  5.56197017e-02  6.15143888e-02  2.13386044e-02\n",
      "  1.42757064e-02 -8.65876861e-03  1.80133637e-02 -2.14710645e-02\n",
      "  5.67414314e-02 -6.51060417e-02 -2.47181077e-02  5.36390953e-02\n",
      " -2.85256617e-02  5.13042770e-02  3.59084867e-02 -2.34959684e-02\n",
      "  3.67335826e-02  8.13580677e-02  4.53695022e-02 -5.87212108e-02\n",
      " -5.89234419e-02 -3.85170020e-02  2.29698457e-02  6.81363568e-02\n",
      " -5.44234850e-02 -1.30923633e-02  3.75272967e-02 -4.13256809e-02\n",
      " -5.04553653e-02 -5.60236089e-02 -2.90316101e-02 -1.10969115e-02\n",
      "  7.34112337e-02 -2.40012212e-03  3.36042345e-02 -1.30136861e-02\n",
      " -1.72345936e-02  4.76706661e-02 -5.12075797e-02 -2.61783376e-02\n",
      "  7.90184829e-03 -3.75406481e-02  3.98516096e-02  1.90929156e-02\n",
      "  6.38586655e-02 -8.68399069e-03  2.99057905e-02  9.44466051e-03\n",
      " -7.21309409e-02  4.64934260e-02  2.97073834e-02  3.95152643e-02\n",
      "  2.51363982e-02 -7.91227259e-03 -4.18615639e-02 -8.17132369e-03\n",
      " -6.95516495e-03 -5.52953174e-03  2.27890778e-02 -3.47597972e-02\n",
      " -5.31464666e-02 -1.75557900e-02 -3.12127173e-02 -1.61671881e-02\n",
      "  3.94536816e-02 -5.93665801e-02 -2.68848408e-02 -1.45100625e-02\n",
      " -2.59814132e-02 -1.64978299e-02  3.57619077e-02  5.11808991e-02\n",
      "  3.15124579e-02 -9.91479959e-03  4.67179269e-02  3.57007906e-02\n",
      " -5.63641451e-03 -9.24349111e-03  3.34681757e-02  4.97004725e-02\n",
      " -8.37174430e-03 -4.80049774e-02  5.98794632e-02 -5.36602437e-02\n",
      " -1.78878084e-02  4.67534140e-02 -2.30093189e-02 -4.71754884e-03\n",
      " -2.33616214e-02 -4.63111140e-02 -3.90830822e-02  5.06937318e-02\n",
      " -8.03212598e-02 -1.06705539e-03 -8.20047688e-03  7.65338540e-02\n",
      " -2.75596511e-04  3.00747231e-02  1.40897948e-02 -4.62418944e-02\n",
      "  6.10929541e-02  6.53405264e-02  5.27407192e-02 -3.45454961e-02\n",
      " -4.22161259e-02  7.78393596e-02  1.06616812e-02 -6.37662187e-02\n",
      " -5.61125809e-03  3.91218858e-03  7.41575379e-04  4.73149354e-03\n",
      "  1.50932623e-02 -3.20530348e-02  3.09856888e-02  6.92638531e-02\n",
      " -2.81752087e-02 -6.80434750e-03  7.15339482e-02 -3.04517932e-02\n",
      "  7.80797144e-03 -7.68775642e-02  1.15937798e-03 -3.56265940e-02\n",
      " -3.33469324e-02 -2.24028099e-02  6.43551201e-02 -5.06543592e-02\n",
      "  2.68929061e-02 -3.79103199e-02  2.32313760e-02 -3.86225730e-02\n",
      "  2.39911210e-02  5.49209304e-02 -2.87132873e-03 -4.80056703e-02\n",
      "  7.57480972e-03  2.70843203e-03 -4.56572995e-02  1.51939935e-03\n",
      " -1.00293485e-02  7.55904650e-04  5.97749129e-02  2.99596954e-02\n",
      " -9.00179222e-02 -6.47020116e-02 -4.19211723e-02  1.43634883e-04\n",
      " -4.42118570e-02  4.73357029e-02  5.34526035e-02 -6.68966351e-03\n",
      " -4.17351425e-02  5.51490076e-02  3.40510681e-02 -6.03361391e-02\n",
      "  5.03292354e-03  5.08005023e-02  7.96706751e-02 -7.45889619e-02\n",
      "  7.24803051e-03  1.17621506e-02 -8.06614105e-03 -5.10273874e-02\n",
      "  5.03970683e-02 -4.70446562e-03  5.18233851e-02  1.90586559e-02\n",
      "  1.22495310e-03 -6.16161786e-02  2.73653753e-02  6.93572611e-02\n",
      " -7.01448023e-02 -5.79721965e-02  7.31678382e-02  2.50939336e-02\n",
      "  6.43439367e-02  2.24138591e-02 -2.95393020e-02  5.18108532e-02\n",
      "  3.31077236e-03  9.87660419e-03 -6.18219562e-03  3.52632478e-02\n",
      " -6.70051493e-04 -7.52561465e-02 -9.25402343e-02 -6.55148700e-02\n",
      "  4.25221846e-02  7.86592253e-03  6.27529398e-02  9.01427306e-03\n",
      "  2.39239968e-02  3.43039595e-02  6.03895895e-02 -5.56003451e-02\n",
      " -1.51206311e-02 -1.09503753e-02  7.02623650e-02 -1.68977231e-02\n",
      " -4.91260402e-02  2.46295389e-02 -8.34488869e-02  4.88740876e-02\n",
      "  2.83027999e-02 -4.56801020e-02  2.13517603e-02 -2.35272348e-02\n",
      "  1.77573264e-02  2.80855764e-02 -2.65471444e-05 -1.25551606e-02\n",
      "  3.98524888e-02  3.95762734e-02 -6.46365061e-02 -6.27968311e-02\n",
      "  1.73042975e-02  5.43546602e-02 -5.39702885e-02 -1.92467980e-02\n",
      " -3.80860120e-02  6.50196001e-02  8.39066785e-03  9.67604294e-03\n",
      "  1.99161470e-03 -5.01980558e-02 -2.30767578e-02 -2.35409532e-02\n",
      " -8.20930079e-02 -7.71238655e-03 -2.46653724e-02  5.56798726e-02\n",
      "  2.44059507e-02  6.07142001e-02  6.09989874e-02  5.28574735e-02\n",
      "  4.78609502e-02  4.92428150e-03  2.78885402e-02  5.16874269e-02\n",
      "  7.32585117e-02  9.43564530e-03 -4.40873541e-02  6.59864768e-02\n",
      "  5.41133396e-02  7.54517689e-02  2.77371233e-04 -6.61929250e-02\n",
      " -4.63327728e-02  6.37062266e-02  4.99945432e-02 -2.32073516e-02\n",
      "  1.82643463e-03  4.63879202e-03 -5.92409149e-02 -6.00943975e-02\n",
      " -5.36683835e-02 -2.92656384e-02 -6.09017946e-02  5.24804182e-02\n",
      " -6.95973337e-02  6.70176297e-02  4.61795069e-02  1.93249099e-02\n",
      " -1.86620858e-02  1.14533482e-02  2.89512649e-02 -2.17325538e-02\n",
      "  3.54018691e-03  9.85096395e-03 -4.59310412e-02 -4.85477000e-02\n",
      " -6.60443977e-02  7.46604800e-02  2.67050732e-02  1.02219321e-02\n",
      "  5.87945320e-02 -2.88803596e-04  6.70477971e-02 -1.95424277e-02\n",
      " -7.36195669e-02 -4.05430757e-02 -4.45277207e-02  5.48210852e-02\n",
      "  5.54598831e-02 -2.78342213e-03  2.46071890e-02  3.81836593e-02\n",
      " -6.34711655e-03  3.71443518e-02  6.09387383e-02 -5.40219173e-02]\n"
     ]
    }
   ],
   "source": [
    "def test(trainer, model, loader, title):\n",
    "    outputs = trainer.predict(model, loader)\n",
    "    embeddings = F.normalize(torch.cat([output['embeddings'] for output in outputs])).numpy()\n",
    "    labels = torch.cat([output['labels'] for output in outputs]).numpy()\n",
    "    \n",
    "    print(embeddings)\n",
    "    print(type(embeddings))\n",
    "    print(embeddings.shape)\n",
    "    print(embeddings[0])\n",
    "\n",
    "test(arcface_trainer, arcface_model, val_loader, f'arcface (epoch {max_epochs})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a643a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "def acc(trainer, model, loader):\n",
    "    outputs = trainer.predict(model, loader)\n",
    "    embeddings = F.normalize(torch.cat([output['embeddings'] for output in outputs])).numpy()\n",
    "    labels = torch.cat([output['labels'] for output in outputs]).numpy()\n",
    "    \n",
    "    svm_clf = svm.SVC(kernel = 'rbf', random_state=100)\n",
    "    svm_clf.fit(embeddings, labels)\n",
    "\n",
    "    true_=(svm_clf.predict(embeddings)==labels).sum()\n",
    "    len_ = len(labels)\n",
    "    print(\"Accuracy :{}%\".format((true_/len_)*100)) ##100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c438bd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:489: PossibleUserWarning: Your `predict_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007954597473144531,
       "initial": 1563,
       "n": 1563,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64266d0d11084b38ba31df5ae6de820f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1563it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :10.724%\n"
     ]
    }
   ],
   "source": [
    "acc(arcface_trainer, arcface_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5becb910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007483005523681641,
       "initial": 1563,
       "n": 1563,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60da21a760e4c5884575fa1b82eb206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1563it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :11.07%\n"
     ]
    }
   ],
   "source": [
    "acc(arcface_trainer, arcface_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6f151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcface",
   "language": "python",
   "name": "arcface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
