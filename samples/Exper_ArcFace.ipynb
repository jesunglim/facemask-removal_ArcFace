{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b210ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e638e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "380430e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bef26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ea4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a08571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/ielab/dataset/ms1m_dataset/train_gan/'\n",
    "test_path = '/home/ielab/dataset/ms1m_dataset/test_gan'\n",
    "\n",
    "og_test_path = '/home/ielab/dataset/ms1m_dataset/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9426517",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = '/home/ielab/project/samples/results/gan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4148c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = os.listdir(train_path)\n",
    "\n",
    "lb = {string : i for i,string in enumerate(col_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d132ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e34e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classe = len(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9b07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((112,112)),\n",
    "    transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba37ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.dir_list = os.listdir(img_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.files = []\n",
    "        for folder in self.dir_list:\n",
    "          folder_list = os.listdir(os.path.join(img_dir, folder))\n",
    "          for file in folder_list:\n",
    "            self.files.append([\n",
    "                os.path.join(self.img_dir, folder+'/'+file),\n",
    "                folder])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.files[idx][0])\n",
    "        image = image.convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        label = self.files[idx][1]\n",
    "        label = lb[label]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beb1b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainset = CustomDataset(train_path, trans)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = CustomDataset(test_path, trans)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc6eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFaceLoss(nn.Module):\n",
    "    def __init__(self, num_classes, embedding_size, margin, scale):\n",
    "        \"\"\"\n",
    "        ArcFace: Additive Angular Margin Loss for Deep Face Recognition\n",
    "        (https://arxiv.org/pdf/1801.07698.pdf)\n",
    "        Args:\n",
    "            num_classes: The number of classes in your training dataset\n",
    "            embedding_size: The size of the embeddings that you pass into\n",
    "            margin: m in the paper, the angular margin penalty in radians\n",
    "            scale: s in the paper, feature scale\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_size = embedding_size\n",
    "        self.margin = margin\n",
    "        self.scale = scale\n",
    "        \n",
    "        self.W = torch.nn.Parameter(torch.Tensor(num_classes, embedding_size))\n",
    "        nn.init.xavier_normal_(self.W)\n",
    "        \n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (None, embedding_size)\n",
    "            labels: (None,)\n",
    "        Returns:\n",
    "            loss: scalar\n",
    "        \"\"\"\n",
    "        cosine = self.get_cosine(embeddings) # (None, n_classes)\n",
    "        mask = self.get_target_mask(labels) # (None, n_classes)\n",
    "        cosine_of_target_classes = cosine[mask == 1] # (None, )\n",
    "        modified_cosine_of_target_classes = self.modify_cosine_of_target_classes(\n",
    "            cosine_of_target_classes\n",
    "        ) # (None, )\n",
    "        diff = (modified_cosine_of_target_classes - cosine_of_target_classes).unsqueeze(1) # (None,1)\n",
    "        logits = cosine + (mask * diff) # (None, n_classes)\n",
    "        logits = self.scale_logits(logits) # (None, n_classes)\n",
    "        return logits\n",
    "        \n",
    "    def get_cosine(self, embeddings):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (None, embedding_size)\n",
    "        Returns:\n",
    "            cosine: (None, n_classes)\n",
    "        \"\"\"\n",
    "        cosine = F.linear(F.normalize(embeddings), F.normalize(self.W))\n",
    "        return cosine\n",
    "    \n",
    "    def get_target_mask(self, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels: (None,)\n",
    "        Returns:\n",
    "            mask: (None, n_classes)\n",
    "        \"\"\"\n",
    "        batch_size = labels.size(0)\n",
    "        onehot = torch.zeros(batch_size, self.num_classes, device=labels.device)\n",
    "        onehot.scatter_(1, labels.unsqueeze(-1), 1)\n",
    "        return onehot\n",
    "        \n",
    "    def modify_cosine_of_target_classes(self, cosine_of_target_classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cosine_of_target_classes: (None,)\n",
    "        Returns:\n",
    "            modified_cosine_of_target_classes: (None,)\n",
    "        \"\"\"\n",
    "        eps = 1e-6\n",
    "        # theta in the paper\n",
    "        angles = torch.acos(torch.clamp(cosine_of_target_classes, -1 + eps, 1 - eps))\n",
    "        return torch.cos(angles + self.margin)\n",
    "    \n",
    "    def scale_logits(self, logits):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits: (None, n_classes)\n",
    "        Returns:\n",
    "            scaled_logits: (None, n_classes)\n",
    "        \"\"\"\n",
    "        return logits * self.scale\n",
    "    \n",
    "class SoftmaxLoss(nn.Module):\n",
    "    def __init__(self, num_classes, embedding_size):\n",
    "        \"\"\"\n",
    "        Regular softmax loss (1 fc layer without bias + CrossEntropyLoss)\n",
    "        Args:\n",
    "            num_classes: The number of classes in your training dataset\n",
    "            embedding_size: The size of the embeddings that you pass into\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.W = torch.nn.Parameter(torch.Tensor(num_classes, embedding_size))\n",
    "        nn.init.xavier_normal_(self.W)\n",
    "        \n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (None, embedding_size)\n",
    "            labels: (None,)\n",
    "        Returns:\n",
    "            loss: scalar\n",
    "        \"\"\"\n",
    "        logits = F.linear(embeddings, self.W)\n",
    "        return nn.CrossEntropyLoss()(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f3c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet50(pretrained = False)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.classifier = nn.Linear(1000, embedding_size)\n",
    "\n",
    "    def forward(self, images):\n",
    "        outputs = self.model(images)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.classifier(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3128edcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :0\n",
      "Epoch: 0 - Batch: 154176 - Loss: 16.572945 - Time:357.68433475494385\n",
      "Epoch: 1 - Batch: 154176 - Loss: 16.799253 - Time:354.8403744697571\n",
      "Epoch: 2 - Batch: 154176 - Loss: 16.459936 - Time:354.91351079940796\n",
      "Epoch: 3 - Batch: 154176 - Loss: 15.805743 - Time:354.9035131931305\n",
      "Epoch: 4 - Batch: 154176 - Loss: 15.308963 - Time:354.9006268978119\n",
      "Epoch: 5 - Batch: 154176 - Loss: 14.646939 - Time:354.92612767219543\n",
      "Epoch: 6 - Batch: 154176 - Loss: 13.073686 - Time:354.97727489471436\n",
      "Epoch: 7 - Batch: 154176 - Loss: 10.913660 - Time:354.95422172546387\n",
      "Epoch: 8 - Batch: 154176 - Loss: 7.061776 - Time:354.89097118377686\n",
      "Epoch: 9 - Batch: 154176 - Loss: 7.079303 - Time:354.9812250137329\n",
      "Epoch: 10 - Batch: 154176 - Loss: 6.961909 - Time:354.96593713760376\n",
      "Epoch: 11 - Batch: 154176 - Loss: 4.173846 - Time:354.93353509902954\n",
      "Epoch: 12 - Batch: 154176 - Loss: 4.219118 - Time:354.89596700668335\n",
      "Epoch: 13 - Batch: 154176 - Loss: 3.103828 - Time:354.96120500564575\n",
      "Epoch: 14 - Batch: 154176 - Loss: 1.877262 - Time:355.068687915802\n",
      "Epoch: 15 - Batch: 154176 - Loss: 2.173865 - Time:355.0296416282654\n",
      "Epoch: 16 - Batch: 154176 - Loss: 1.709071 - Time:354.96049213409424\n",
      "Epoch: 17 - Batch: 154176 - Loss: 1.775287 - Time:354.99619817733765\n",
      "Epoch: 18 - Batch: 154176 - Loss: 1.142136 - Time:355.01568937301636\n",
      "Epoch: 19 - Batch: 154176 - Loss: 0.747441 - Time:354.9984657764435\n",
      "Epoch: 20 - Batch: 154176 - Loss: 0.677649 - Time:354.95540499687195\n",
      "Epoch: 21 - Batch: 154176 - Loss: 0.664386 - Time:355.0261676311493\n",
      "Epoch: 22 - Batch: 154176 - Loss: 0.762288 - Time:355.0078773498535\n",
      "Epoch: 23 - Batch: 154176 - Loss: 0.323351 - Time:355.01988530158997\n",
      "Epoch: 24 - Batch: 154176 - Loss: 1.159060 - Time:354.95909237861633\n",
      "Epoch: 25 - Batch: 154176 - Loss: 0.341945 - Time:355.01440811157227\n",
      "Epoch: 26 - Batch: 154176 - Loss: 0.786348 - Time:355.01237988471985\n",
      "Epoch: 27 - Batch: 154176 - Loss: 0.650987 - Time:355.00938725471497\n",
      "Epoch: 28 - Batch: 154176 - Loss: 1.488238 - Time:354.94474959373474\n",
      "Epoch: 29 - Batch: 154176 - Loss: 0.789448 - Time:354.90280199050903\n",
      "Epoch: 30 - Batch: 154176 - Loss: 0.246787 - Time:354.9651653766632\n",
      "Epoch: 31 - Batch: 154176 - Loss: 0.512539 - Time:354.91380310058594\n",
      "Epoch: 32 - Batch: 154176 - Loss: 0.864275 - Time:354.9216651916504\n",
      "Epoch: 33 - Batch: 154176 - Loss: 0.314860 - Time:354.96101212501526\n",
      "Epoch: 34 - Batch: 154176 - Loss: 0.450579 - Time:354.9849967956543\n",
      "Epoch: 35 - Batch: 154176 - Loss: 0.606605 - Time:354.99498867988586\n",
      "Epoch: 36 - Batch: 154176 - Loss: 0.345288 - Time:354.95472526550293\n",
      "Epoch: 37 - Batch: 154176 - Loss: 0.126909 - Time:354.91632318496704\n",
      "Epoch: 38 - Batch: 154176 - Loss: 0.129544 - Time:354.976571559906\n",
      "Epoch: 39 - Batch: 154176 - Loss: 0.701933 - Time:354.8988718986511\n",
      "Epoch: 40 - Batch: 154176 - Loss: 0.107643 - Time:354.90453720092773\n",
      "Epoch: 41 - Batch: 154176 - Loss: 0.299361 - Time:354.9191589355469\n",
      "Epoch: 42 - Batch: 154176 - Loss: 0.239947 - Time:354.9799053668976\n",
      "Epoch: 43 - Batch: 154176 - Loss: 0.062150 - Time:354.94236946105957\n",
      "Epoch: 44 - Batch: 154176 - Loss: 0.591590 - Time:354.87697887420654\n",
      "Epoch: 45 - Batch: 154176 - Loss: 0.108811 - Time:354.89282274246216\n",
      "Epoch: 46 - Batch: 154176 - Loss: 0.206336 - Time:354.89481377601624\n",
      "Epoch: 47 - Batch: 154176 - Loss: 0.432746 - Time:354.942125082016\n",
      "Epoch: 48 - Batch: 154176 - Loss: 0.180054 - Time:354.8497896194458\n",
      "Epoch: 49 - Batch: 154176 - Loss: 0.033791 - Time:354.91325402259827\n",
      "Epoch: 50 - Batch: 154176 - Loss: 0.108675 - Time:354.993839263916\n",
      "Epoch: 51 - Batch: 154176 - Loss: 0.049693 - Time:354.93050026893616\n",
      "Epoch: 52 - Batch: 154176 - Loss: 0.183372 - Time:354.86564469337463\n",
      "Epoch: 53 - Batch: 154176 - Loss: 0.050353 - Time:354.9378628730774\n",
      "Epoch: 54 - Batch: 154176 - Loss: 0.272709 - Time:354.9094994068146\n",
      "Epoch: 55 - Batch: 154176 - Loss: 0.066309 - Time:354.9558434486389\n",
      "Epoch: 56 - Batch: 154176 - Loss: 0.169025 - Time:354.8755581378937\n",
      "Epoch: 57 - Batch: 154176 - Loss: 0.254129 - Time:355.05635714530945\n",
      "Epoch: 58 - Batch: 154176 - Loss: 0.203152 - Time:354.9150035381317\n",
      "Epoch: 59 - Batch: 154176 - Loss: 0.153561 - Time:354.9081292152405\n",
      "Epoch: 60 - Batch: 154176 - Loss: 0.144089 - Time:354.84638023376465\n",
      "Epoch: 61 - Batch: 154176 - Loss: 0.219911 - Time:354.8914067745209\n",
      "Epoch: 62 - Batch: 154176 - Loss: 0.514623 - Time:354.946293592453\n",
      "Epoch: 63 - Batch: 154176 - Loss: 0.181413 - Time:354.93016052246094\n",
      "Epoch: 64 - Batch: 154176 - Loss: 0.410253 - Time:354.8803162574768\n",
      "Epoch: 65 - Batch: 154176 - Loss: 0.717416 - Time:354.9396002292633\n",
      "Epoch: 66 - Batch: 154176 - Loss: 0.264085 - Time:354.87104201316833\n",
      "Epoch: 67 - Batch: 154176 - Loss: 0.202224 - Time:354.8906743526459\n",
      "Epoch: 68 - Batch: 154176 - Loss: 0.056246 - Time:354.81890964508057\n",
      "Epoch: 69 - Batch: 154176 - Loss: 0.731643 - Time:354.9017539024353\n",
      "Epoch: 70 - Batch: 154176 - Loss: 0.504838 - Time:354.8723442554474\n",
      "Epoch: 71 - Batch: 154176 - Loss: 0.035198 - Time:354.8640787601471\n",
      "Epoch: 72 - Batch: 154176 - Loss: 0.590950 - Time:355.0163607597351\n",
      "Epoch: 73 - Batch: 154176 - Loss: 0.366656 - Time:354.8986577987671\n",
      "Epoch: 74 - Batch: 154176 - Loss: 0.079328 - Time:354.92653155326843\n",
      "Epoch: 75 - Batch: 154176 - Loss: 0.260650 - Time:354.90033888816833\n",
      "Epoch: 76 - Batch: 154176 - Loss: 0.030294 - Time:354.82965874671936\n",
      "Epoch: 77 - Batch: 154176 - Loss: 0.023060 - Time:354.8734481334686\n",
      "Epoch: 78 - Batch: 154176 - Loss: 0.025356 - Time:354.9479224681854\n",
      "Epoch: 79 - Batch: 154176 - Loss: 0.042643 - Time:354.90736293792725\n",
      "Epoch: 80 - Batch: 154176 - Loss: 0.064076 - Time:354.8341066837311\n",
      "Epoch: 81 - Batch: 154176 - Loss: 0.062298 - Time:354.8638205528259\n",
      "Epoch: 82 - Batch: 154176 - Loss: 0.047308 - Time:354.8555588722229\n",
      "Epoch: 83 - Batch: 154176 - Loss: 0.041988 - Time:354.9296066761017\n",
      "Epoch: 84 - Batch: 154176 - Loss: 0.039917 - Time:354.830771446228\n",
      "Epoch: 85 - Batch: 154176 - Loss: 0.044471 - Time:354.89028120040894\n",
      "Epoch: 86 - Batch: 154176 - Loss: 0.161266 - Time:354.9072017669678\n",
      "Epoch: 87 - Batch: 154176 - Loss: 0.020073 - Time:354.8849039077759\n",
      "Epoch: 88 - Batch: 154176 - Loss: 0.124909 - Time:354.91384291648865\n",
      "Epoch: 89 - Batch: 154176 - Loss: 0.115221 - Time:354.8731791973114\n",
      "Epoch: 90 - Batch: 154176 - Loss: 0.345163 - Time:354.8777174949646\n",
      "Epoch: 91 - Batch: 154176 - Loss: 0.056771 - Time:354.89856815338135\n",
      "Epoch: 92 - Batch: 154176 - Loss: 0.051747 - Time:354.82832169532776\n",
      "Epoch: 93 - Batch: 154176 - Loss: 0.037207 - Time:354.87712597846985\n",
      "Epoch: 94 - Batch: 154176 - Loss: 0.105578 - Time:354.85208916664124\n",
      "Epoch: 95 - Batch: 154176 - Loss: 0.039447 - Time:354.88195395469666\n",
      "Epoch: 96 - Batch: 154176 - Loss: 0.154083 - Time:354.8232910633087\n",
      "Epoch: 97 - Batch: 154176 - Loss: 0.098403 - Time:354.91560649871826\n",
      "Epoch: 98 - Batch: 154176 - Loss: 0.102499 - Time:354.9115467071533\n",
      "Epoch: 99 - Batch: 154176 - Loss: 0.328225 - Time:354.8670303821564\n",
      "train acc : 0.9586045908442484\n",
      "test acc : 0.6315570898331041\n",
      "epoch :1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Batch: 154176 - Loss: 0.050388 - Time:355.15546202659607\n",
      "Epoch: 1 - Batch: 154176 - Loss: 0.182207 - Time:355.0204565525055\n",
      "Epoch: 2 - Batch: 154176 - Loss: 0.015397 - Time:354.96494579315186\n",
      "Epoch: 3 - Batch: 154176 - Loss: 0.367057 - Time:354.9551160335541\n",
      "Epoch: 4 - Batch: 154176 - Loss: 0.016822 - Time:354.96637630462646\n",
      "Epoch: 5 - Batch: 154176 - Loss: 0.173450 - Time:355.0339078903198\n",
      "Epoch: 6 - Batch: 154176 - Loss: 0.021558 - Time:354.97234654426575\n",
      "Epoch: 7 - Batch: 154176 - Loss: 0.018314 - Time:354.9522588253021\n",
      "Epoch: 8 - Batch: 154176 - Loss: 0.154696 - Time:354.98444414138794\n",
      "Epoch: 9 - Batch: 154176 - Loss: 0.073390 - Time:355.0129282474518\n",
      "Epoch: 10 - Batch: 154176 - Loss: 0.030394 - Time:355.01617527008057\n",
      "Epoch: 11 - Batch: 154176 - Loss: 0.028555 - Time:354.9887173175812\n",
      "Epoch: 12 - Batch: 154176 - Loss: 0.579171 - Time:354.97189807891846\n",
      "Epoch: 13 - Batch: 154176 - Loss: 0.047128 - Time:354.99556946754456\n",
      "Epoch: 14 - Batch: 154176 - Loss: 0.100585 - Time:355.00454354286194\n",
      "Epoch: 15 - Batch: 154176 - Loss: 0.042411 - Time:354.98927307128906\n",
      "Epoch: 16 - Batch: 154176 - Loss: 0.051217 - Time:354.96966528892517\n",
      "Epoch: 17 - Batch: 154176 - Loss: 0.113099 - Time:354.9821698665619\n",
      "Epoch: 18 - Batch: 154176 - Loss: 0.209903 - Time:354.98638939857483\n",
      "Epoch: 19 - Batch: 154176 - Loss: 0.037039 - Time:354.97729206085205\n",
      "Epoch: 20 - Batch: 154176 - Loss: 0.181034 - Time:355.0272386074066\n",
      "Epoch: 21 - Batch: 154176 - Loss: 1.109650 - Time:355.0575222969055\n",
      "Epoch: 22 - Batch: 154176 - Loss: 0.197629 - Time:354.9778733253479\n",
      "Epoch: 23 - Batch: 154176 - Loss: 0.020877 - Time:354.9195463657379\n",
      "Epoch: 24 - Batch: 154176 - Loss: 0.101249 - Time:354.9394807815552\n",
      "Epoch: 25 - Batch: 154176 - Loss: 0.029192 - Time:355.01271319389343\n",
      "Epoch: 26 - Batch: 154176 - Loss: 0.012576 - Time:354.98747181892395\n",
      "Epoch: 27 - Batch: 154176 - Loss: 0.035982 - Time:354.97562527656555\n",
      "Epoch: 28 - Batch: 154176 - Loss: 0.408794 - Time:354.9753487110138\n",
      "Epoch: 29 - Batch: 154176 - Loss: 0.016692 - Time:354.9639947414398\n",
      "Epoch: 30 - Batch: 154176 - Loss: 0.032761 - Time:355.0104115009308\n",
      "Epoch: 31 - Batch: 154176 - Loss: 0.027445 - Time:355.00711488723755\n",
      "Epoch: 32 - Batch: 154176 - Loss: 0.130216 - Time:354.9859902858734\n",
      "Epoch: 33 - Batch: 154176 - Loss: 0.035092 - Time:354.9982969760895\n",
      "Epoch: 34 - Batch: 154176 - Loss: 0.011146 - Time:355.0084705352783\n",
      "Epoch: 35 - Batch: 154176 - Loss: 0.010142 - Time:355.0084640979767\n",
      "Epoch: 36 - Batch: 154176 - Loss: 0.013146 - Time:355.02097749710083\n",
      "Epoch: 37 - Batch: 154176 - Loss: 0.292322 - Time:355.1353235244751\n",
      "Epoch: 38 - Batch: 154176 - Loss: 0.079524 - Time:355.0193009376526\n",
      "Epoch: 39 - Batch: 154176 - Loss: 0.438491 - Time:355.0158488750458\n",
      "Epoch: 40 - Batch: 154176 - Loss: 0.018413 - Time:354.97979521751404\n",
      "Epoch: 41 - Batch: 154176 - Loss: 0.014849 - Time:354.9936649799347\n",
      "Epoch: 42 - Batch: 154176 - Loss: 0.019832 - Time:354.95377016067505\n",
      "Epoch: 43 - Batch: 154176 - Loss: 0.012144 - Time:354.98047399520874\n",
      "Epoch: 44 - Batch: 154176 - Loss: 0.090221 - Time:355.04298734664917\n",
      "Epoch: 45 - Batch: 154176 - Loss: 0.184502 - Time:355.02007365226746\n",
      "Epoch: 46 - Batch: 154176 - Loss: 0.017329 - Time:354.994167804718\n",
      "Epoch: 47 - Batch: 154176 - Loss: 0.041473 - Time:354.9775011539459\n",
      "Epoch: 48 - Batch: 154176 - Loss: 0.023261 - Time:354.9707684516907\n",
      "Epoch: 49 - Batch: 154176 - Loss: 0.071759 - Time:355.13353061676025\n",
      "Epoch: 50 - Batch: 154176 - Loss: 0.010395 - Time:355.01823806762695\n",
      "Epoch: 51 - Batch: 154176 - Loss: 0.011945 - Time:355.0403323173523\n",
      "Epoch: 52 - Batch: 154176 - Loss: 0.018508 - Time:355.03494930267334\n",
      "Epoch: 53 - Batch: 154176 - Loss: 0.022186 - Time:355.0649485588074\n",
      "Epoch: 54 - Batch: 154176 - Loss: 0.098830 - Time:354.9931764602661\n",
      "Epoch: 55 - Batch: 154176 - Loss: 0.387810 - Time:354.9874601364136\n",
      "Epoch: 56 - Batch: 154176 - Loss: 0.118536 - Time:355.04353404045105\n",
      "Epoch: 57 - Batch: 154176 - Loss: 0.020137 - Time:355.0452125072479\n",
      "Epoch: 58 - Batch: 154176 - Loss: 0.015901 - Time:355.0313057899475\n",
      "Epoch: 59 - Batch: 154176 - Loss: 0.054283 - Time:354.99536657333374\n",
      "Epoch: 60 - Batch: 154176 - Loss: 0.094946 - Time:355.0385982990265\n",
      "Epoch: 61 - Batch: 154176 - Loss: 0.155604 - Time:355.06718134880066\n",
      "Epoch: 62 - Batch: 154176 - Loss: 0.025387 - Time:355.05866956710815\n",
      "Epoch: 63 - Batch: 154176 - Loss: 0.010674 - Time:354.97564005851746\n",
      "Epoch: 64 - Batch: 154176 - Loss: 0.017550 - Time:355.0297374725342\n",
      "Epoch: 65 - Batch: 154176 - Loss: 0.020512 - Time:355.06651425361633\n",
      "Epoch: 66 - Batch: 154176 - Loss: 0.070324 - Time:355.04176473617554\n",
      "Epoch: 67 - Batch: 154176 - Loss: 0.013460 - Time:355.0498812198639\n",
      "Epoch: 68 - Batch: 154176 - Loss: 0.009453 - Time:354.9990918636322\n",
      "Epoch: 69 - Batch: 154176 - Loss: 0.026947 - Time:355.0059242248535\n",
      "Epoch: 70 - Batch: 154176 - Loss: 0.039100 - Time:355.0095601081848\n",
      "Epoch: 71 - Batch: 154176 - Loss: 0.027707 - Time:355.00247073173523\n",
      "Epoch: 72 - Batch: 154176 - Loss: 0.014725 - Time:354.99364709854126\n",
      "Epoch: 73 - Batch: 154176 - Loss: 0.022594 - Time:355.06024074554443\n",
      "Epoch: 74 - Batch: 154176 - Loss: 0.014193 - Time:355.05330204963684\n",
      "Epoch: 75 - Batch: 154176 - Loss: 0.011596 - Time:355.02554273605347\n",
      "Epoch: 76 - Batch: 154176 - Loss: 0.013482 - Time:355.0499937534332\n",
      "Epoch: 77 - Batch: 154176 - Loss: 0.034503 - Time:355.06761360168457\n",
      "Epoch: 78 - Batch: 154176 - Loss: 0.065643 - Time:355.05091881752014\n",
      "Epoch: 79 - Batch: 154176 - Loss: 0.010735 - Time:355.01092290878296\n",
      "Epoch: 80 - Batch: 154176 - Loss: 0.081169 - Time:355.0348644256592\n",
      "Epoch: 81 - Batch: 154176 - Loss: 0.032743 - Time:355.0587570667267\n",
      "Epoch: 82 - Batch: 154176 - Loss: 0.016450 - Time:355.0750982761383\n",
      "Epoch: 83 - Batch: 154176 - Loss: 0.007585 - Time:355.01239585876465\n",
      "Epoch: 84 - Batch: 154176 - Loss: 0.017553 - Time:355.0420835018158\n",
      "Epoch: 85 - Batch: 154176 - Loss: 0.010469 - Time:355.0815680027008\n",
      "Epoch: 86 - Batch: 154176 - Loss: 0.057334 - Time:355.07639169692993\n",
      "Epoch: 87 - Batch: 154176 - Loss: 0.006598 - Time:355.00866961479187\n",
      "Epoch: 88 - Batch: 154176 - Loss: 0.030788 - Time:355.02746319770813\n",
      "Epoch: 89 - Batch: 154176 - Loss: 0.008803 - Time:355.0648868083954\n",
      "Epoch: 90 - Batch: 154176 - Loss: 0.008009 - Time:355.07214879989624\n",
      "Epoch: 91 - Batch: 154176 - Loss: 0.019301 - Time:355.1421637535095\n",
      "Epoch: 92 - Batch: 154176 - Loss: 0.012892 - Time:355.04540181159973\n",
      "Epoch: 93 - Batch: 154176 - Loss: 0.035971 - Time:355.06029081344604\n",
      "Epoch: 94 - Batch: 154176 - Loss: 0.052362 - Time:355.0184738636017\n",
      "Epoch: 95 - Batch: 154176 - Loss: 0.160378 - Time:354.9816188812256\n",
      "Epoch: 96 - Batch: 154176 - Loss: 0.022856 - Time:355.0396685600281\n",
      "Epoch: 97 - Batch: 154176 - Loss: 0.009502 - Time:355.04357504844666\n",
      "Epoch: 98 - Batch: 154176 - Loss: 0.010492 - Time:355.02851033210754\n",
      "Epoch: 99 - Batch: 154176 - Loss: 0.007531 - Time:355.0364365577698\n",
      "train acc : 0.9801711840228245\n",
      "test acc : 0.6804578607210527\n",
      "epoch :2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Batch: 154176 - Loss: 0.029301 - Time:355.14159655570984\n",
      "Epoch: 1 - Batch: 154176 - Loss: 0.015841 - Time:355.03322076797485\n",
      "Epoch: 2 - Batch: 154176 - Loss: 0.373524 - Time:355.04896545410156\n",
      "Epoch: 3 - Batch: 154176 - Loss: 0.007534 - Time:355.00809478759766\n",
      "Epoch: 4 - Batch: 154176 - Loss: 0.016918 - Time:355.05256390571594\n",
      "Epoch: 5 - Batch: 154176 - Loss: 0.048696 - Time:355.0219178199768\n",
      "Epoch: 6 - Batch: 154176 - Loss: 0.027094 - Time:355.02407598495483\n",
      "Epoch: 7 - Batch: 154176 - Loss: 0.019335 - Time:355.09976053237915\n",
      "Epoch: 8 - Batch: 154176 - Loss: 0.012522 - Time:355.0571217536926\n",
      "Epoch: 9 - Batch: 154176 - Loss: 0.027545 - Time:355.0568497180939\n",
      "Epoch: 10 - Batch: 154176 - Loss: 0.015253 - Time:355.075966835022\n",
      "Epoch: 11 - Batch: 154176 - Loss: 0.007637 - Time:355.0751795768738\n",
      "Epoch: 12 - Batch: 154176 - Loss: 0.008777 - Time:355.10882115364075\n",
      "Epoch: 13 - Batch: 154176 - Loss: 0.008426 - Time:355.1550934314728\n",
      "Epoch: 14 - Batch: 154176 - Loss: 0.019301 - Time:355.1423797607422\n",
      "Epoch: 15 - Batch: 154176 - Loss: 0.007875 - Time:355.13854122161865\n",
      "Epoch: 16 - Batch: 154176 - Loss: 0.195226 - Time:355.15368938446045\n",
      "Epoch: 17 - Batch: 154176 - Loss: 0.035015 - Time:355.1260142326355\n",
      "Epoch: 18 - Batch: 154176 - Loss: 0.006412 - Time:355.09403824806213\n",
      "Epoch: 19 - Batch: 154176 - Loss: 0.009508 - Time:355.0830490589142\n",
      "Epoch: 20 - Batch: 154176 - Loss: 0.009587 - Time:355.17774391174316\n",
      "Epoch: 21 - Batch: 154176 - Loss: 0.006082 - Time:355.11285161972046\n",
      "Epoch: 22 - Batch: 154176 - Loss: 0.011427 - Time:355.2497227191925\n",
      "Epoch: 23 - Batch: 154176 - Loss: 0.016997 - Time:355.1491677761078\n",
      "Epoch: 24 - Batch: 154176 - Loss: 0.010279 - Time:355.1715154647827\n",
      "Epoch: 25 - Batch: 154176 - Loss: 0.046703 - Time:355.1397557258606\n",
      "Epoch: 26 - Batch: 154176 - Loss: 0.015304 - Time:355.11494421958923\n",
      "Epoch: 27 - Batch: 154176 - Loss: 0.019164 - Time:355.13847947120667\n",
      "Epoch: 28 - Batch: 154176 - Loss: 0.014966 - Time:355.13288974761963\n",
      "Epoch: 29 - Batch: 154176 - Loss: 0.052053 - Time:355.10640120506287\n",
      "Epoch: 30 - Batch: 154176 - Loss: 0.007968 - Time:355.12054324150085\n",
      "Epoch: 31 - Batch: 154176 - Loss: 0.007709 - Time:355.1268951892853\n",
      "Epoch: 32 - Batch: 154176 - Loss: 0.009171 - Time:355.21550989151\n",
      "Epoch: 33 - Batch: 154176 - Loss: 0.005921 - Time:355.10593724250793\n",
      "Epoch: 34 - Batch: 154176 - Loss: 0.223327 - Time:355.132301568985\n",
      "Epoch: 35 - Batch: 154176 - Loss: 0.015984 - Time:355.1284246444702\n",
      "Epoch: 36 - Batch: 154176 - Loss: 0.059534 - Time:355.1145827770233\n",
      "Epoch: 37 - Batch: 154176 - Loss: 0.141246 - Time:355.1172263622284\n",
      "Epoch: 38 - Batch: 154176 - Loss: 0.007801 - Time:355.1210992336273\n",
      "Epoch: 39 - Batch: 154176 - Loss: 0.121885 - Time:355.1348614692688\n",
      "Epoch: 40 - Batch: 154176 - Loss: 0.007168 - Time:355.158084154129\n",
      "Epoch: 41 - Batch: 154176 - Loss: 0.095292 - Time:355.1448736190796\n",
      "Epoch: 42 - Batch: 154176 - Loss: 0.016043 - Time:355.08483934402466\n",
      "Epoch: 43 - Batch: 154176 - Loss: 0.013128 - Time:355.1365342140198\n",
      "Epoch: 44 - Batch: 154176 - Loss: 0.039754 - Time:355.1699604988098\n",
      "Epoch: 45 - Batch: 154176 - Loss: 0.013252 - Time:355.20130157470703\n",
      "Epoch: 46 - Batch: 154176 - Loss: 0.074757 - Time:355.12935280799866\n",
      "Epoch: 47 - Batch: 154176 - Loss: 0.087034 - Time:355.1213457584381\n",
      "Epoch: 48 - Batch: 154176 - Loss: 0.018878 - Time:355.1489408016205\n",
      "Epoch: 49 - Batch: 154176 - Loss: 0.007513 - Time:355.14763045310974\n",
      "Epoch: 50 - Batch: 154176 - Loss: 0.008447 - Time:355.1275968551636\n",
      "Epoch: 51 - Batch: 154176 - Loss: 0.007596 - Time:355.114235162735\n",
      "Epoch: 52 - Batch: 154176 - Loss: 0.069819 - Time:355.16306257247925\n",
      "Epoch: 53 - Batch: 154176 - Loss: 0.023908 - Time:355.1373326778412\n",
      "Epoch: 54 - Batch: 154176 - Loss: 0.014462 - Time:355.10478115081787\n",
      "Epoch: 55 - Batch: 154176 - Loss: 0.009679 - Time:355.12265610694885\n",
      "Epoch: 56 - Batch: 154176 - Loss: 0.007560 - Time:355.15002059936523\n",
      "Epoch: 57 - Batch: 154176 - Loss: 0.008007 - Time:355.1200485229492\n",
      "Epoch: 58 - Batch: 154176 - Loss: 0.005264 - Time:355.1146790981293\n",
      "Epoch: 59 - Batch: 154176 - Loss: 0.015622 - Time:355.17029190063477\n",
      "Epoch: 60 - Batch: 154176 - Loss: 0.208304 - Time:355.1937801837921\n",
      "Epoch: 61 - Batch: 154176 - Loss: 0.004790 - Time:355.2123398780823\n",
      "Epoch: 62 - Batch: 154176 - Loss: 0.012857 - Time:355.1244113445282\n",
      "Epoch: 63 - Batch: 154176 - Loss: 0.005121 - Time:355.128493309021\n",
      "Epoch: 64 - Batch: 154176 - Loss: 0.063647 - Time:355.1839323043823\n",
      "Epoch: 65 - Batch: 154176 - Loss: 0.011178 - Time:355.1945090293884\n",
      "Epoch: 66 - Batch: 154176 - Loss: 0.005017 - Time:355.11313033103943\n",
      "Epoch: 67 - Batch: 154176 - Loss: 0.005313 - Time:355.1513659954071\n",
      "Epoch: 68 - Batch: 154176 - Loss: 0.005501 - Time:355.1451361179352\n",
      "Epoch: 69 - Batch: 154176 - Loss: 0.008436 - Time:355.13240027427673\n",
      "Epoch: 70 - Batch: 154176 - Loss: 0.007968 - Time:355.11888885498047\n",
      "Epoch: 71 - Batch: 154176 - Loss: 0.004479 - Time:355.12550115585327\n",
      "Epoch: 72 - Batch: 154176 - Loss: 0.014646 - Time:355.17710185050964\n",
      "Epoch: 73 - Batch: 154176 - Loss: 0.008016 - Time:355.24186849594116\n",
      "Epoch: 74 - Batch: 154176 - Loss: 0.013523 - Time:355.2335584163666\n",
      "Epoch: 75 - Batch: 154176 - Loss: 0.008795 - Time:355.2569386959076\n",
      "Epoch: 76 - Batch: 154176 - Loss: 0.018728 - Time:355.2367923259735\n",
      "Epoch: 77 - Batch: 154176 - Loss: 0.017752 - Time:355.22495555877686\n",
      "Epoch: 78 - Batch: 154176 - Loss: 0.008406 - Time:355.1434314250946\n",
      "Epoch: 79 - Batch: 154176 - Loss: 0.004750 - Time:355.19968914985657\n",
      "Epoch: 80 - Batch: 154176 - Loss: 0.039304 - Time:355.20716738700867\n",
      "Epoch: 81 - Batch: 154176 - Loss: 0.021670 - Time:355.17499709129333\n",
      "Epoch: 82 - Batch: 154176 - Loss: 0.050751 - Time:355.12288427352905\n",
      "Epoch: 83 - Batch: 154176 - Loss: 0.014770 - Time:355.2006278038025\n",
      "Epoch: 84 - Batch: 154176 - Loss: 0.006341 - Time:355.2083251476288\n",
      "Epoch: 85 - Batch: 154176 - Loss: 0.005463 - Time:355.17701745033264\n",
      "Epoch: 86 - Batch: 154176 - Loss: 0.006322 - Time:355.12478852272034\n",
      "Epoch: 87 - Batch: 154176 - Loss: 0.006938 - Time:355.1767907142639\n",
      "Epoch: 88 - Batch: 154176 - Loss: 0.004617 - Time:355.1547405719757\n",
      "Epoch: 89 - Batch: 154176 - Loss: 0.013726 - Time:355.16801476478577\n",
      "Epoch: 90 - Batch: 154176 - Loss: 0.011161 - Time:355.0891191959381\n",
      "Epoch: 91 - Batch: 154176 - Loss: 0.021787 - Time:355.12726306915283\n",
      "Epoch: 92 - Batch: 154176 - Loss: 0.010924 - Time:355.16098523139954\n",
      "Epoch: 93 - Batch: 154176 - Loss: 0.138937 - Time:355.11694955825806\n",
      "Epoch: 94 - Batch: 154176 - Loss: 0.008186 - Time:355.0883800983429\n",
      "Epoch: 95 - Batch: 154176 - Loss: 0.039981 - Time:355.1234452724457\n",
      "Epoch: 96 - Batch: 154176 - Loss: 0.080089 - Time:355.14997720718384\n",
      "Epoch: 97 - Batch: 154176 - Loss: 0.106174 - Time:355.11319851875305\n",
      "Epoch: 98 - Batch: 154176 - Loss: 0.015502 - Time:355.10208535194397\n",
      "Epoch: 99 - Batch: 154176 - Loss: 0.037546 - Time:355.07929730415344\n",
      "train acc : 0.9818376345480483\n",
      "test acc : 0.6924234952111507\n",
      "epoch :3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Batch: 154176 - Loss: 0.036050 - Time:355.2459325790405\n",
      "Epoch: 1 - Batch: 154176 - Loss: 0.028912 - Time:355.08333110809326\n",
      "Epoch: 2 - Batch: 154176 - Loss: 0.009572 - Time:355.1014151573181\n",
      "Epoch: 3 - Batch: 154176 - Loss: 0.008002 - Time:355.14819836616516\n",
      "Epoch: 4 - Batch: 154176 - Loss: 0.015061 - Time:355.0971682071686\n",
      "Epoch: 5 - Batch: 154176 - Loss: 0.012050 - Time:355.0558297634125\n",
      "Epoch: 6 - Batch: 154176 - Loss: 0.088712 - Time:355.0619671344757\n",
      "Epoch: 7 - Batch: 154176 - Loss: 0.009223 - Time:355.1595878601074\n",
      "Epoch: 8 - Batch: 154176 - Loss: 0.006119 - Time:355.08141899108887\n",
      "Epoch: 9 - Batch: 154176 - Loss: 0.111193 - Time:355.0972936153412\n",
      "Epoch: 10 - Batch: 154176 - Loss: 0.008907 - Time:355.1262857913971\n",
      "Epoch: 11 - Batch: 154176 - Loss: 0.014611 - Time:355.09205889701843\n",
      "Epoch: 12 - Batch: 154176 - Loss: 0.005718 - Time:355.11952114105225\n",
      "Epoch: 13 - Batch: 154176 - Loss: 0.047975 - Time:355.06729555130005\n",
      "Epoch: 14 - Batch: 154176 - Loss: 0.008870 - Time:355.1056067943573\n",
      "Epoch: 15 - Batch: 154176 - Loss: 0.004303 - Time:355.1461787223816\n",
      "Epoch: 16 - Batch: 154176 - Loss: 0.050823 - Time:355.1237325668335\n",
      "Epoch: 17 - Batch: 154176 - Loss: 0.004584 - Time:355.1025221347809\n",
      "Epoch: 18 - Batch: 154176 - Loss: 0.003705 - Time:355.1269624233246\n",
      "Epoch: 19 - Batch: 154176 - Loss: 0.007979 - Time:355.1739733219147\n",
      "Epoch: 20 - Batch: 154176 - Loss: 0.006209 - Time:355.10455536842346\n",
      "Epoch: 21 - Batch: 154176 - Loss: 0.008492 - Time:355.10778856277466\n",
      "Epoch: 22 - Batch: 154176 - Loss: 0.003967 - Time:355.1027705669403\n",
      "Epoch: 23 - Batch: 154176 - Loss: 0.013696 - Time:355.1128406524658\n",
      "Epoch: 24 - Batch: 154176 - Loss: 0.004523 - Time:355.07331800460815\n",
      "Epoch: 25 - Batch: 154176 - Loss: 0.004371 - Time:355.0716230869293\n",
      "Epoch: 26 - Batch: 154176 - Loss: 0.100304 - Time:355.09292364120483\n",
      "Epoch: 27 - Batch: 154176 - Loss: 0.019351 - Time:355.11325693130493\n",
      "Epoch: 28 - Batch: 154176 - Loss: 0.005006 - Time:355.0948398113251\n",
      "Epoch: 29 - Batch: 154176 - Loss: 0.016553 - Time:355.0587668418884\n",
      "Epoch: 30 - Batch: 154176 - Loss: 0.011599 - Time:355.0822229385376\n",
      "Epoch: 31 - Batch: 154176 - Loss: 0.038592 - Time:355.12223649024963\n",
      "Epoch: 32 - Batch: 154176 - Loss: 0.046861 - Time:355.11585092544556\n",
      "Epoch: 33 - Batch: 154176 - Loss: 0.146186 - Time:355.0554230213165\n",
      "Epoch: 34 - Batch: 154176 - Loss: 0.004123 - Time:355.07423281669617\n",
      "Epoch: 35 - Batch: 154176 - Loss: 0.004666 - Time:355.07851910591125\n",
      "Epoch: 36 - Batch: 154176 - Loss: 0.006488 - Time:355.0763761997223\n",
      "Epoch: 37 - Batch: 154176 - Loss: 0.017213 - Time:355.10475492477417\n",
      "Epoch: 38 - Batch: 154176 - Loss: 0.005659 - Time:355.10387420654297\n",
      "Epoch: 39 - Batch: 154176 - Loss: 0.008465 - Time:355.11908197402954\n",
      "Epoch: 40 - Batch: 154176 - Loss: 0.003670 - Time:355.11203694343567\n",
      "Epoch: 41 - Batch: 154176 - Loss: 0.006056 - Time:355.0853431224823\n",
      "Epoch: 42 - Batch: 154176 - Loss: 0.004879 - Time:355.0537967681885\n",
      "Epoch: 43 - Batch: 154176 - Loss: 0.004437 - Time:355.1532943248749\n",
      "Epoch: 44 - Batch: 154176 - Loss: 0.046959 - Time:355.08047890663147\n",
      "Epoch: 45 - Batch: 154176 - Loss: 0.022606 - Time:355.0515513420105\n",
      "Epoch: 46 - Batch: 154176 - Loss: 0.007667 - Time:355.0948967933655\n",
      "Epoch: 47 - Batch: 154176 - Loss: 0.003387 - Time:355.10939049720764\n",
      "Epoch: 48 - Batch: 154176 - Loss: 0.005462 - Time:355.10660767555237\n",
      "Epoch: 49 - Batch: 154176 - Loss: 0.003759 - Time:355.07043170928955\n",
      "Epoch: 50 - Batch: 154176 - Loss: 0.005948 - Time:355.05285453796387\n",
      "Epoch: 51 - Batch: 154176 - Loss: 0.016897 - Time:355.1623342037201\n",
      "Epoch: 52 - Batch: 154176 - Loss: 0.004282 - Time:355.14497780799866\n",
      "Epoch: 53 - Batch: 154176 - Loss: 0.006494 - Time:355.0903012752533\n",
      "Epoch: 54 - Batch: 154176 - Loss: 0.062215 - Time:355.1206707954407\n",
      "Epoch: 55 - Batch: 154176 - Loss: 0.014312 - Time:355.1097025871277\n",
      "Epoch: 56 - Batch: 154176 - Loss: 0.003565 - Time:355.11720275878906\n",
      "Epoch: 57 - Batch: 154176 - Loss: 0.004421 - Time:355.0621106624603\n",
      "Epoch: 58 - Batch: 154176 - Loss: 0.170886 - Time:355.08216643333435\n",
      "Epoch: 59 - Batch: 154176 - Loss: 0.183678 - Time:355.1246531009674\n",
      "Epoch: 60 - Batch: 154176 - Loss: 0.007009 - Time:355.1452651023865\n",
      "Epoch: 61 - Batch: 154176 - Loss: 0.003527 - Time:355.1048927307129\n",
      "Epoch: 62 - Batch: 154176 - Loss: 0.070340 - Time:355.1150345802307\n",
      "Epoch: 63 - Batch: 154176 - Loss: 0.040501 - Time:355.1075167655945\n",
      "Epoch: 64 - Batch: 154176 - Loss: 0.004467 - Time:355.08383560180664\n",
      "Epoch: 65 - Batch: 154176 - Loss: 0.005029 - Time:355.09253334999084\n",
      "Epoch: 66 - Batch: 154176 - Loss: 0.250706 - Time:355.10476088523865\n",
      "Epoch: 67 - Batch: 154176 - Loss: 0.004331 - Time:355.1449179649353\n",
      "Epoch: 68 - Batch: 154176 - Loss: 0.003670 - Time:355.0853567123413\n",
      "Epoch: 69 - Batch: 154176 - Loss: 0.004692 - Time:355.06351494789124\n",
      "Epoch: 70 - Batch: 154176 - Loss: 0.009392 - Time:355.0622389316559\n",
      "Epoch: 71 - Batch: 154176 - Loss: 0.010050 - Time:355.1692817211151\n",
      "Epoch: 72 - Batch: 154176 - Loss: 0.100985 - Time:355.1100957393646\n",
      "Epoch: 73 - Batch: 154176 - Loss: 0.004294 - Time:355.0920853614807\n",
      "Epoch: 74 - Batch: 154176 - Loss: 0.003815 - Time:355.1100525856018\n",
      "Epoch: 75 - Batch: 154176 - Loss: 0.067999 - Time:355.1489429473877\n",
      "Epoch: 76 - Batch: 154176 - Loss: 0.008251 - Time:355.0843243598938\n",
      "Epoch: 77 - Batch: 154176 - Loss: 0.004932 - Time:355.08145022392273\n",
      "Epoch: 78 - Batch: 154176 - Loss: 0.011078 - Time:355.1128556728363\n",
      "Epoch: 79 - Batch: 154176 - Loss: 0.007323 - Time:355.1569631099701\n",
      "Epoch: 80 - Batch: 154176 - Loss: 0.006619 - Time:355.1061828136444\n",
      "Epoch: 81 - Batch: 154176 - Loss: 0.032513 - Time:355.07143092155457\n",
      "Epoch: 82 - Batch: 154176 - Loss: 0.007602 - Time:355.09501814842224\n",
      "Epoch: 83 - Batch: 154176 - Loss: 0.010104 - Time:355.1232581138611\n",
      "Epoch: 84 - Batch: 154176 - Loss: 0.005163 - Time:355.1553227901459\n",
      "Epoch: 85 - Batch: 154176 - Loss: 0.003250 - Time:355.1063539981842\n",
      "Epoch: 86 - Batch: 154176 - Loss: 0.006494 - Time:355.1240978240967\n",
      "Epoch: 87 - Batch: 154176 - Loss: 0.550914 - Time:355.14536786079407\n",
      "Epoch: 88 - Batch: 154176 - Loss: 0.009498 - Time:355.0733003616333\n",
      "Epoch: 89 - Batch: 154176 - Loss: 0.003816 - Time:355.1140651702881\n",
      "Epoch: 90 - Batch: 154176 - Loss: 0.002859 - Time:355.1485769748688\n",
      "Epoch: 91 - Batch: 154176 - Loss: 0.078000 - Time:355.1365501880646\n",
      "Epoch: 92 - Batch: 154176 - Loss: 0.003785 - Time:355.13309717178345\n",
      "Epoch: 93 - Batch: 154176 - Loss: 0.098456 - Time:355.0976302623749\n",
      "Epoch: 94 - Batch: 154176 - Loss: 0.013314 - Time:355.0925395488739\n",
      "Epoch: 95 - Batch: 154176 - Loss: 0.011090 - Time:355.13485860824585\n",
      "Epoch: 96 - Batch: 154176 - Loss: 0.004315 - Time:355.117066860199\n",
      "Epoch: 97 - Batch: 154176 - Loss: 0.027658 - Time:355.0452814102173\n",
      "Epoch: 98 - Batch: 154176 - Loss: 0.009819 - Time:355.0945131778717\n",
      "Epoch: 99 - Batch: 154176 - Loss: 0.003471 - Time:355.11366415023804\n",
      "train acc : 0.9824666061470626\n",
      "test acc : 0.6874399771588756\n",
      "epoch :4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Batch: 154176 - Loss: 0.007321 - Time:355.1912908554077\n",
      "Epoch: 1 - Batch: 154176 - Loss: 0.018132 - Time:355.08872628211975\n",
      "Epoch: 2 - Batch: 154176 - Loss: 0.004213 - Time:355.11781334877014\n",
      "Epoch: 3 - Batch: 154176 - Loss: 0.009181 - Time:355.1110680103302\n",
      "Epoch: 4 - Batch: 154176 - Loss: 0.002648 - Time:355.1199731826782\n",
      "Epoch: 5 - Batch: 154176 - Loss: 0.004245 - Time:355.0886559486389\n",
      "Epoch: 6 - Batch: 154176 - Loss: 0.004584 - Time:355.116286277771\n",
      "Epoch: 7 - Batch: 154176 - Loss: 0.003216 - Time:355.1081006526947\n",
      "Epoch: 8 - Batch: 154176 - Loss: 0.008734 - Time:355.11406087875366\n",
      "Epoch: 9 - Batch: 154176 - Loss: 0.003900 - Time:355.0896887779236\n",
      "Epoch: 10 - Batch: 154176 - Loss: 0.015795 - Time:355.13466906547546\n",
      "Epoch: 11 - Batch: 154176 - Loss: 0.003123 - Time:355.31604528427124\n",
      "Epoch: 12 - Batch: 154176 - Loss: 0.007725 - Time:355.1312212944031\n",
      "Epoch: 13 - Batch: 154176 - Loss: 0.031019 - Time:355.14549803733826\n",
      "Epoch: 14 - Batch: 154176 - Loss: 0.004701 - Time:355.1404104232788\n",
      "Epoch: 15 - Batch: 154176 - Loss: 0.004107 - Time:355.1512281894684\n",
      "Epoch: 16 - Batch: 154176 - Loss: 0.005016 - Time:355.10093808174133\n",
      "Epoch: 17 - Batch: 154176 - Loss: 0.005556 - Time:355.14226269721985\n",
      "Epoch: 18 - Batch: 154176 - Loss: 0.007414 - Time:355.15718245506287\n",
      "Epoch: 19 - Batch: 154176 - Loss: 0.008855 - Time:355.13414454460144\n",
      "Epoch: 20 - Batch: 154176 - Loss: 0.005908 - Time:355.11225628852844\n",
      "Epoch: 21 - Batch: 154176 - Loss: 0.004640 - Time:355.15953302383423\n",
      "Epoch: 22 - Batch: 154176 - Loss: 0.021934 - Time:355.1952292919159\n",
      "Epoch: 23 - Batch: 154176 - Loss: 0.004770 - Time:355.15470266342163\n",
      "Epoch: 24 - Batch: 154176 - Loss: 0.090884 - Time:355.10934948921204\n",
      "Epoch: 25 - Batch: 154176 - Loss: 0.003167 - Time:355.32708048820496\n",
      "Epoch: 26 - Batch: 154176 - Loss: 0.039892 - Time:355.5528392791748\n",
      "Epoch: 27 - Batch: 154176 - Loss: 0.008802 - Time:355.2331078052521\n",
      "Epoch: 28 - Batch: 154176 - Loss: 0.004452 - Time:355.17295718193054\n",
      "Epoch: 29 - Batch: 154176 - Loss: 0.002450 - Time:355.1904499530792\n",
      "Epoch: 30 - Batch: 154176 - Loss: 0.041493 - Time:355.19639801979065\n",
      "Epoch: 31 - Batch: 154176 - Loss: 0.006528 - Time:355.2266983985901\n",
      "Epoch: 32 - Batch: 154176 - Loss: 0.003123 - Time:355.19557452201843\n",
      "Epoch: 33 - Batch: 154176 - Loss: 0.009490 - Time:355.209068775177\n",
      "Epoch: 34 - Batch: 154176 - Loss: 0.006034 - Time:355.2259168624878\n",
      "Epoch: 35 - Batch: 154176 - Loss: 0.004190 - Time:355.2433867454529\n",
      "Epoch: 36 - Batch: 154176 - Loss: 0.002699 - Time:355.89098858833313\n",
      "Epoch: 37 - Batch: 154176 - Loss: 0.003580 - Time:355.9230525493622\n",
      "Epoch: 38 - Batch: 154176 - Loss: 0.004737 - Time:355.95578479766846\n",
      "Epoch: 39 - Batch: 154176 - Loss: 0.003161 - Time:355.9164650440216\n",
      "Epoch: 40 - Batch: 154176 - Loss: 0.003134 - Time:355.90124797821045\n",
      "Epoch: 41 - Batch: 154176 - Loss: 0.006990 - Time:355.9428322315216\n",
      "Epoch: 42 - Batch: 154176 - Loss: 0.139425 - Time:355.93518686294556\n",
      "Epoch: 43 - Batch: 154176 - Loss: 0.055481 - Time:355.9189672470093\n",
      "Epoch: 44 - Batch: 154176 - Loss: 0.003462 - Time:355.9026446342468\n",
      "Epoch: 45 - Batch: 154176 - Loss: 0.003885 - Time:355.93764781951904\n",
      "Epoch: 46 - Batch: 154176 - Loss: 0.170962 - Time:355.9562222957611\n",
      "Epoch: 47 - Batch: 154176 - Loss: 0.005073 - Time:355.95784640312195\n",
      "Epoch: 48 - Batch: 154176 - Loss: 0.010430 - Time:355.9015402793884\n",
      "Epoch: 49 - Batch: 154176 - Loss: 0.004658 - Time:355.8973243236542\n",
      "Epoch: 50 - Batch: 154176 - Loss: 0.005229 - Time:355.96690034866333\n",
      "Epoch: 51 - Batch: 154176 - Loss: 0.011025 - Time:355.9815526008606\n",
      "Epoch: 52 - Batch: 154176 - Loss: 0.002319 - Time:355.96177649497986\n",
      "Epoch: 53 - Batch: 154176 - Loss: 0.010140 - Time:355.99823117256165\n",
      "Epoch: 54 - Batch: 154176 - Loss: 0.007509 - Time:356.1420922279358\n",
      "Epoch: 55 - Batch: 154176 - Loss: 0.020546 - Time:356.05002665519714\n",
      "Epoch: 56 - Batch: 154176 - Loss: 0.002932 - Time:356.03617000579834\n",
      "Epoch: 57 - Batch: 154176 - Loss: 0.091938 - Time:356.036030292511\n",
      "Epoch: 58 - Batch: 154176 - Loss: 0.003510 - Time:356.090074300766\n",
      "Epoch: 59 - Batch: 154176 - Loss: 0.005353 - Time:356.05164647102356\n",
      "Epoch: 60 - Batch: 154176 - Loss: 0.002750 - Time:355.97272968292236\n",
      "Epoch: 61 - Batch: 154176 - Loss: 0.007837 - Time:356.0159411430359\n",
      "Epoch: 62 - Batch: 154176 - Loss: 0.004299 - Time:356.07509994506836\n",
      "Epoch: 63 - Batch: 154176 - Loss: 0.002844 - Time:356.0101749897003\n",
      "Epoch: 64 - Batch: 154176 - Loss: 0.003546 - Time:356.04276990890503\n",
      "Epoch: 65 - Batch: 154176 - Loss: 0.110292 - Time:356.0590879917145\n",
      "Epoch: 66 - Batch: 154176 - Loss: 0.060226 - Time:356.0336697101593\n",
      "Epoch: 67 - Batch: 154176 - Loss: 0.002602 - Time:356.0590510368347\n",
      "Epoch: 68 - Batch: 154176 - Loss: 0.003468 - Time:356.00574684143066\n",
      "Epoch: 69 - Batch: 154176 - Loss: 0.007946 - Time:356.02695417404175\n",
      "Epoch: 70 - Batch: 154176 - Loss: 0.002751 - Time:356.0598678588867\n",
      "Epoch: 71 - Batch: 154176 - Loss: 0.005115 - Time:356.04702496528625\n",
      "Epoch: 72 - Batch: 154176 - Loss: 0.006145 - Time:355.99877858161926\n",
      "Epoch: 73 - Batch: 154176 - Loss: 0.008523 - Time:356.0612037181854\n",
      "Epoch: 74 - Batch: 154176 - Loss: 0.004109 - Time:356.1193177700043\n",
      "Epoch: 75 - Batch: 154176 - Loss: 0.033293 - Time:356.04689168930054\n",
      "Epoch: 76 - Batch: 154176 - Loss: 0.015843 - Time:356.01853466033936\n",
      "Epoch: 77 - Batch: 154176 - Loss: 0.005858 - Time:356.06210136413574\n",
      "Epoch: 78 - Batch: 154176 - Loss: 0.008790 - Time:356.0707700252533\n",
      "Epoch: 79 - Batch: 154176 - Loss: 0.002944 - Time:356.0307343006134\n",
      "Epoch: 80 - Batch: 154176 - Loss: 0.009022 - Time:356.0168309211731\n",
      "Epoch: 81 - Batch: 154176 - Loss: 0.003644 - Time:355.9948751926422\n",
      "Epoch: 82 - Batch: 154176 - Loss: 0.004718 - Time:356.01965069770813\n",
      "Epoch: 83 - Batch: 154176 - Loss: 0.005891 - Time:355.98527693748474\n",
      "Epoch: 84 - Batch: 154176 - Loss: 0.007681 - Time:356.0324025154114\n",
      "Epoch: 85 - Batch: 154176 - Loss: 0.133740 - Time:356.02700304985046\n",
      "Epoch: 86 - Batch: 154176 - Loss: 0.003762 - Time:356.0622675418854\n",
      "Epoch: 87 - Batch: 154176 - Loss: 0.048306 - Time:356.0508108139038\n",
      "Epoch: 88 - Batch: 154176 - Loss: 0.002657 - Time:355.99433422088623\n",
      "Epoch: 89 - Batch: 154176 - Loss: 0.006872 - Time:355.95712542533875\n",
      "Epoch: 90 - Batch: 154176 - Loss: 0.011608 - Time:356.0246412754059\n",
      "Epoch: 91 - Batch: 154176 - Loss: 0.003055 - Time:356.05770349502563\n",
      "Epoch: 92 - Batch: 154176 - Loss: 0.011005 - Time:356.01521039009094\n",
      "Epoch: 93 - Batch: 154176 - Loss: 0.005630 - Time:355.9940266609192\n",
      "Epoch: 94 - Batch: 154176 - Loss: 0.071261 - Time:356.1221191883087\n",
      "Epoch: 95 - Batch: 154176 - Loss: 0.008009 - Time:356.0582778453827\n",
      "Epoch: 96 - Batch: 154176 - Loss: 0.004852 - Time:356.0326614379883\n",
      "Epoch: 97 - Batch: 154176 - Loss: 0.004073 - Time:356.0490279197693\n",
      "Epoch: 98 - Batch: 154176 - Loss: 0.004276 - Time:356.06337571144104\n",
      "Epoch: 99 - Batch: 154176 - Loss: 0.004153 - Time:356.02736377716064\n",
      "train acc : 0.9848463234340552\n",
      "test acc : 0.7034028084200691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ielab/anaconda3/envs/arcface/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Epoch  \n",
    "repeat_num = 5\n",
    "\n",
    "\n",
    "embedding_size = 512\n",
    "max_epochs = 100\n",
    "\n",
    "embedder = Embedder(embedding_size=embedding_size)\n",
    "arcface = ArcFaceLoss(num_classes=num_classe, embedding_size=embedding_size,margin=0.3, scale=30.0)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    embedder = nn.DataParallel(embedder)\n",
    "    arcface = nn.DataParallel(arcface)\n",
    "embedder = embedder.to(device)\n",
    "arcface = arcface.to(device)\n",
    "\n",
    "optimizer = optim.Adam(embedder.parameters(), lr=1e-3 ) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.9)\n",
    "\n",
    "\n",
    "for num in range(repeat_num):\n",
    "    start = time.time()\n",
    "    print(f'epoch :{num}')\n",
    "    for epoch in range(max_epochs):\n",
    "        e_time = time.time()\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            embedder.train()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = embedder(images)\n",
    "\n",
    "            logits = arcface(embeddings, labels)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "        \n",
    "        print(f'Epoch: {epoch} - Batch: {i*batch_size} - Loss: {loss:.6f} - Time:{time.time() - e_time}')\n",
    "        with open(result_path + 'loss-'+str(num) +'.txt', 'a') as file:\n",
    "            file.write(f'{loss:.6f}\\n')\n",
    "                    \n",
    "    torch.save(embedder, result_path + str(num)  + '_model.pth')\n",
    "    \n",
    "    #   \n",
    "    train_results = []\n",
    "    train_labels = []\n",
    "    test_results = []\n",
    "    test_labels = []\n",
    "\n",
    "    embedder.eval()\n",
    "    with torch.no_grad():\n",
    "      for img, label in trainloader:\n",
    "        img = img.cuda()\n",
    "        train_results.append(embedder(img).cpu().detach().numpy())\n",
    "        train_labels.append(label)\n",
    "\n",
    "    train_results = np.concatenate(train_results)\n",
    "    train_labels = np.concatenate(train_labels)\n",
    "\n",
    "    embedder.eval()\n",
    "    with torch.no_grad():\n",
    "      for img, label in testloader:\n",
    "        img = img.cuda()\n",
    "        test_results.append(embedder(img).cpu().detach().numpy())\n",
    "        test_labels.append(label)\n",
    "\n",
    "    test_results = np.concatenate(test_results)\n",
    "    test_labels = np.concatenate(test_labels)\n",
    "    \n",
    "    # kNN  \n",
    "    k = 50\n",
    "    model = KNeighborsClassifier(n_neighbors = k)\n",
    "    #  \n",
    "    model.fit(train_results, train_labels)\n",
    "    #knn \n",
    "    train_pred = model.predict(train_results)\n",
    "    train_acc = (train_pred == train_labels).mean()\n",
    "    with open(result_path + 'train_acc-'+str(num) +'.txt', 'a') as file:\n",
    "        file.write(f'{train_acc:.6f}\\n')\n",
    "    print(f'train acc : {train_acc}')\n",
    "    test_pred = model.predict(test_results)\n",
    "    test_acc = (test_pred == test_labels).mean()\n",
    "    with open(result_path + 'test_acc-'+str(num) +'.txt', 'a') as file:\n",
    "        file.write(f'{test_acc:.6f}\\n')\n",
    "    print(f'test acc : {test_acc}')\n",
    "    # F1-Score\n",
    "    f1 = metrics.classification_report(test_labels, test_pred)\n",
    "    with open(result_path + 'test_f1-'+str(num) +'.txt', 'a') as file:\n",
    "        file.write(f'{f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85bb0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65ffb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f01e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa970df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc5e720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedder = torch.load(result_path + \"gan_model.pth\", map_location=device)\n",
    "#print(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bd25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0c1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5a25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcface",
   "language": "python",
   "name": "arcface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
